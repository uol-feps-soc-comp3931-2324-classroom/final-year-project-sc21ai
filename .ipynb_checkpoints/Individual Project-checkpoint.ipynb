{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "881ee93d-69fe-4fae-90ee-fe49c89eed57",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset,DataLoader \u001b[38;5;66;03m#For working with data.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msegmentation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeeplabv3\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DeepLabHead\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import pandas as pd #For reading csv files.\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt #For plotting.\n",
    "\n",
    "import PIL.Image as Image #For working with image files.\n",
    "\n",
    "#Importing torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "\n",
    "from torch.utils.data import Dataset,DataLoader #For working with data.\n",
    "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
    "\n",
    "from torchvision import models,transforms #For pretrained models,image transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17055bd-5210-4cb1-9b94-c50c5db0c7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #Use GPU if it's available or else use CPU.\n",
    "print(device) #Prints the device we're using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1594f4b3-7d0e-413f-88ba-037c0fcb4646",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"aptos2019-blindness-detection/\"\n",
    "\n",
    "train_df = pd.read_csv(f\"{path}train.csv\")\n",
    "print(f'No.of.training_samples: {len(train_df)}')\n",
    "\n",
    "test_df = pd.read_csv(f'{path}test.csv')\n",
    "print(f'No.of.testing_samples: {len(test_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2501c6-fa66-4741-9085-c619c813411c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histogram of label counts.\n",
    "train_df.diagnosis.hist()\n",
    "plt.xticks([0,1,2,3,4])\n",
    "plt.grid(False)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05158119-d29a-4842-8621-7d28a1bc35a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#As you can see,the data is imbalanced.\n",
    "#So we've to calculate weights for each class,which can be used in calculating loss.\n",
    "\n",
    "from sklearn.utils import class_weight #For calculating weights for each class.\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced',classes=np.array([0,1,2,3,4]),y=train_df['diagnosis'].values)\n",
    "class_weights = torch.tensor(class_weights,dtype=torch.float).to(device)\n",
    " \n",
    "print(class_weights) #Prints the calculated weights for the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7a609d-7067-4bee-9868-bcb21e2b7889",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For getting a random image from our training set.\n",
    "num = int(np.random.randint(0,len(train_df)-1,(1,))) #Picks a random number.\n",
    "sample_image = (f'{path}train_images/{train_df[\"id_code\"][num]}.png')#Image file.\n",
    "sample_image = Image.open(sample_image) \n",
    "plt.imshow(sample_image)\n",
    "plt.axis('off')\n",
    "plt.title(f'Class: {train_df[\"diagnosis\"][num]}') #Class of the random image.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6b3ac3-aaa8-49ab-8d7f-5ea02725f232",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCropAndSave:\n",
    "    def __init__(self, target_quality=72, crop_percentage=0.95):\n",
    "        self.target_quality = target_quality\n",
    "        self.crop_percentage = crop_percentage\n",
    "\n",
    "    def __call__(self, img):\n",
    "        # Convert image to numpy array\n",
    "        img_array = np.array(img)\n",
    "\n",
    "        # Thresholding to detect black areas\n",
    "        gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)\n",
    "        _, thresh = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Find contours and get bounding box of non-black area\n",
    "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        x, y, w, h = cv2.boundingRect(contours[0])\n",
    "\n",
    "        # Crop the image to remove black space\n",
    "        cropped_image = img_array[y:y+h, x:x+w]\n",
    "        cropped_img = Image.fromarray(cropped_image)\n",
    "\n",
    "        # Perform cropping to 90% of the image size\n",
    "        width, height = cropped_img.size\n",
    "        crop_size = int(min(width, height) * self.crop_percentage)\n",
    "        left = (width - crop_size) / 2\n",
    "        top = (height - crop_size) / 2\n",
    "        right = (width + crop_size) / 2\n",
    "        bottom = (height + crop_size) / 2\n",
    "        cropped_img = cropped_img.crop((left, top, right, bottom))\n",
    "\n",
    "        # Save the cropped image with desired JPEG quality\n",
    "        cropped_img.save('preprocessed_image.jpg', format='JPEG', quality=self.target_quality)\n",
    "\n",
    "        return cropped_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98b9892-5ffe-4438-b9e7-d5782fc9a1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset): # Inherits from the Dataset class.\n",
    "    '''\n",
    "    dataset class overloads the __init__, __len__, __getitem__ methods of the Dataset class. \n",
    "    \n",
    "    Attributes :\n",
    "        df:  DataFrame object for the csv file.\n",
    "        data_path: Location of the dataset.\n",
    "        image_transform: Transformations to apply to the image.\n",
    "        train: A boolean indicating whether it is a training_set or not.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,df,data_path,image_transform=None,train=True): # Constructor.\n",
    "        super(Dataset,self).__init__() #Calls the constructor of the Dataset class.\n",
    "        self.df = df\n",
    "        self.data_path = data_path\n",
    "        self.image_transform = image_transform\n",
    "        self.train = train\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df) #Returns the number of samples in the dataset.\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        image_id = self.df['id_code'][index]\n",
    "        image = Image.open(f'{self.data_path}/{image_id}.png') #Image.\n",
    "        if self.image_transform :\n",
    "            image = self.image_transform(image) #Applies transformation to the image.\n",
    "        \n",
    "        if self.train :\n",
    "            label = self.df['diagnosis'][index] #Label.\n",
    "            return image,label #If train == True, return image & label.\n",
    "        \n",
    "        else:\n",
    "            return image #If train != True, return image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5083c3ec-ed7c-4154-97b0-69fba7f7b84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform = transforms.Compose([CustomCropAndSave(),\n",
    "                                      transforms.Resize([256, 256]),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))]) #Transformations to apply to the image.\n",
    "data_set = dataset(train_df,f'{path}train_images',image_transform=image_transform)\n",
    "\n",
    "#Split the data_set so that valid_set contains 0.1 samples of the data_set. \n",
    "train_set,valid_set = torch.utils.data.random_split(data_set,[3302,360])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b5c522-1296-4959-b3c1-35e17a92f810",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_set,batch_size=32,shuffle=True) #DataLoader for train_set.\n",
    "valid_dataloader = DataLoader(valid_set,batch_size=32,shuffle=False) #DataLoader for validation_set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821b96f8-64cd-4066-bb82-9857e643d5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since we've less data, we'll use Transfer learning.\n",
    "model = models.resnet34(pretrained=True) #Downloads the resnet18 model which is pretrained on Imagenet dataset.in_channels=\n",
    "\n",
    "#Replace the Final layer of pretrained resnet18 with 4 new layers.\n",
    "model.fc = nn.Sequential(nn.Linear(512,256),nn.Linear(256,128),nn.Linear(128,64),nn.Linear(64,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665ffb98-c91f-4135-b220-4035b6c618a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device) #Moves the model to the device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ede8bf-8376-4914-aae9-575308a6f0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader,model,loss_fn,optimizer):\n",
    "    '''\n",
    "    train function updates the weights of the model based on the\n",
    "    loss using the optimizer in order to get a lower loss.\n",
    "    \n",
    "    Args :\n",
    "         dataloader: Iterator for the batches in the data_set.\n",
    "         model: Given an input produces an output by multiplying the input with the model weights.\n",
    "         loss_fn: Calculates the discrepancy between the label & the model's predictions.\n",
    "         optimizer: Updates the model weights.\n",
    "         \n",
    "    Returns :\n",
    "         Average loss per batch which is calculated by dividing the losses for all the batches\n",
    "         with the number of batches.\n",
    "    '''\n",
    "\n",
    "    model.train() #Sets the model for training.\n",
    "    \n",
    "    total = 0\n",
    "    correct = 0\n",
    "    running_loss = 0\n",
    "    \n",
    "    for batch,(x,y) in enumerate(dataloader): #Iterates through the batches.\n",
    "        \n",
    "        output = model(x.to(device)) #model's predictions.\n",
    "        loss   = loss_fn(output,y.to(device)) #loss calculation.\n",
    "       \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        total        += y.size(0)\n",
    "        predictions   = output.argmax(dim=1).cpu().detach() #Index for the highest score for all the samples in the batch.\n",
    "        correct      += (predictions == y.cpu().detach()).sum().item() #No.of.cases where model's predictions are equal to the label.\n",
    "        \n",
    "        optimizer.zero_grad() #Gradient values are set to zero.\n",
    "        loss.backward() #Calculates the gradients.\n",
    "        optimizer.step() #Updates the model weights.\n",
    "             \n",
    "    \n",
    "    avg_loss = running_loss/len(dataloader) # Average loss for a single batch\n",
    "    \n",
    "    print(f'\\nTraining Loss per batch = {avg_loss:.6f}',end='\\t')\n",
    "    print(f'Accuracy on Training set = {100*(correct/total):.6f}% [{correct}/{total}]') #Prints the Accuracy.\n",
    "    \n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb94005-4645-41f0-8576-33c65089e179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(dataloader,model,loss_fn):\n",
    "    '''\n",
    "    validate function calculates the average loss per batch and the accuracy of the model's predictions.\n",
    "    \n",
    "    Args :\n",
    "         dataloader: Iterator for the batches in the data_set.\n",
    "         model: Given an input produces an output by multiplying the input with the model weights.\n",
    "         loss_fn: Calculates the discrepancy between the label & the model's predictions.\n",
    "    \n",
    "    Returns :\n",
    "         Average loss per batch which is calculated by dividing the losses for all the batches\n",
    "         with the number of batches.\n",
    "    '''\n",
    "    \n",
    "    model.eval() #Sets the model for evaluation.\n",
    "    \n",
    "    total = 0\n",
    "    correct = 0\n",
    "    running_loss = 0\n",
    "    \n",
    "    with torch.no_grad(): #No need to calculate the gradients.\n",
    "        \n",
    "        for x,y in dataloader:\n",
    "            \n",
    "            output        = model(x.to(device)) #model's output.\n",
    "            loss          = loss_fn(output,y.to(device)).item() #loss calculation.\n",
    "            running_loss += loss\n",
    "            \n",
    "            total        += y.size(0)\n",
    "            predictions   = output.argmax(dim=1).cpu().detach()\n",
    "            correct      += (predictions == y.cpu().detach()).sum().item()\n",
    "            \n",
    "    avg_loss = running_loss/len(dataloader) #Average loss per batch.      \n",
    "    \n",
    "    print(f'\\nValidation Loss per batch = {avg_loss:.6f}',end='\\t')\n",
    "    print(f'Accuracy on Validation set = {100*(correct/total):.6f}% [{correct}/{total}]') #Prints the Accuracy.\n",
    "    \n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3910d1c9-529e-404c-adad-7c215fea4077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(train_dataloader,valid_dataloader,model,loss_fn,optimizer,nb_epochs):\n",
    "    '''\n",
    "    optimize function calls the train & validate functions for (nb_epochs) times.\n",
    "    \n",
    "    Args :\n",
    "        train_dataloader: DataLoader for the train_set.\n",
    "        valid_dataloader: DataLoader for the valid_set.\n",
    "        model: Given an input produces an output by multiplying the input with the model weights.\n",
    "        loss_fn: Calculates the discrepancy between the label & the model's predictions.\n",
    "        optimizer: Updates the model weights.\n",
    "        nb_epochs: Number of epochs.\n",
    "        \n",
    "    Returns :\n",
    "        Tuple of lists containing losses for all the epochs.\n",
    "    '''\n",
    "    #Lists to store losses for all the epochs.\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "\n",
    "    for epoch in range(nb_epochs):\n",
    "        print(f'\\nEpoch {epoch+1}/{nb_epochs}')\n",
    "        print('-------------------------------')\n",
    "        train_loss = train(train_dataloader,model,loss_fn,optimizer) #Calls the train function.\n",
    "        train_losses.append(train_loss)\n",
    "        valid_loss = validate(valid_dataloader,model,loss_fn) #Calls the validate function.\n",
    "        valid_losses.append(valid_loss)\n",
    "    \n",
    "    print('\\nTraining has completed!')\n",
    "    \n",
    "    return train_losses,valid_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daba4077-d58e-4822-b148-3a2371d57e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn   = nn.CrossEntropyLoss(weight=class_weights) #CrossEntropyLoss with class_weights.\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.001) \n",
    "nb_epochs = 10\n",
    "#Call the optimize function.\n",
    "train_losses, valid_losses = optimize(train_dataloader,valid_dataloader,model,loss_fn,optimizer,nb_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0894bc-5ed0-4b7e-b035-bf60726688f0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Plot the graph of train_losses & valid_losses against nb_epochs.\n",
    "epochs = range(nb_epochs)\n",
    "plt.plot(epochs, train_losses, 'g', label='Training loss')\n",
    "plt.plot(epochs, valid_losses, 'b', label='validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b116c6a2-8dcc-41e6-bf1f-5a4b634a36fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = dataset(test_df,f'{path}test_images',image_transform = image_transform,train = False )\n",
    "\n",
    "test_dataloader = DataLoader(test_set, batch_size=32, shuffle=False) #DataLoader for test_set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0569055-4856-4b15-82a0-d95d1d0e1d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader,model):\n",
    "    '''\n",
    "    test function predicts the labels given an image batches.\n",
    "    \n",
    "    Args :\n",
    "         dataloader: DataLoader for the test_set.\n",
    "         model: Given an input produces an output by multiplying the input with the model weights.\n",
    "         \n",
    "    Returns :\n",
    "         List of predicted labels.\n",
    "    '''\n",
    "    \n",
    "    model.eval() #Sets the model for evaluation.\n",
    "    \n",
    "    labels = [] #List to store the predicted labels.\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for batch,x in enumerate(dataloader):\n",
    "            \n",
    "            output = model(x.to(device))\n",
    "            \n",
    "            predictions = output.argmax(dim=1).cpu().detach().tolist() #Predicted labels for an image batch.\n",
    "            labels.extend(predictions)\n",
    "                \n",
    "    print('Testing has completed')\n",
    "            \n",
    "    return labels                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d814b9e1-ed67-4ddb-a55a-e256a5bc0610",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = test(test_dataloader,model) #Calls the test function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d4b663-448a-4ce5-a1b1-603c9930bb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0f7ef2-f508-463f-8373-9833353176ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
